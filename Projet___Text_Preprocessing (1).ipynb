{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YshIO02QhEq"
      },
      "source": [
        "## Projet de processing de texte\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-rBZ3KjgG14"
      },
      "source": [
        "# Dans ce projet , nous sauvegardons un fichier .csv lors de chaque opérations pour faciliter l'opérations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtNRpOiIQrrV"
      },
      "source": [
        "Pour tester vos fonctions, utiliser la données sur les tweets de Donald Trump.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eSIJPmcXtZY"
      },
      "source": [
        "Nous commençons par importer les modules nécéssaires"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAtJLPIUIlPl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwx7mfjm_3f-"
      },
      "source": [
        "### 1. Suppression des balises HTML\n",
        "**Description :** Cette fonction retire toutes les balises HTML d'un texte. Cela est utile lorsque l'on traite du texte extrait de pages web."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HB9NXZU40cs",
        "outputId": "a3a8991c-16ee-4501-ddce-41d8fa55d7da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoRgcnrI4_JI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Chemins des fichiers - Updated to raw CSV data URLs\n",
        "file2_path = 'https://drive.google.com/uc?export=download&id=19UCbXkAmiAetOnhLb4EfnV19eSAlQRya'  # Replace with your actual raw data URL\n",
        "\n",
        "\n",
        "# Charger les fichiers CSV dans des DataFrames\n",
        "df2 = pd.read_csv(file2_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXTw47ZT_Y7_"
      },
      "outputs": [],
      "source": [
        "# Fonction : strip_html_tags\n",
        "\n",
        "def strip_html_tags(text):\n",
        "    \"\"\"\n",
        "    Supprime les balises HTML du texte et normalise les retours à la ligne.\n",
        "    \"\"\"\n",
        "    if pd.isna(text):  # Vérifie si la valeur est NaN\n",
        "        return text\n",
        "    # Utilise une expression régulière pour supprimer les balises HTML\n",
        "    clean_text = re.sub(r'<[^>]+>', '', str(text))\n",
        "    # Normalise les retours à la ligne\n",
        "    clean_text = re.sub(r'\\n+', '\\n', clean_text).strip()\n",
        "    return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odiFU9ha8vyX"
      },
      "outputs": [],
      "source": [
        "# Appliquer la fonction à toutes les cellules du DataFrame\n",
        "df = df.applymap(strip_html_tags)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLNUTlQMYK-r"
      },
      "source": [
        "sauvegarde dans le fichier \"fichier_nettoye_02.csv , notre fichier sans balise html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymhNdKVQZbqx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkHBgMpi80Nr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Chemins de sortie pour les fichiers nettoyés\n",
        "nouveau_chemin2 = '/content/drive/My Drive/data mining/fichier_nettoye_02.csv'\n",
        "\n",
        "#créer un nouveau chemin si inexistany\n",
        "os.makedirs(os.path.dirname(nouveau_chemin1), exist_ok=True)\n",
        "\n",
        "# Sauvegarder les fichiers\n",
        "df2.to_csv(nouveau_chemin2, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqUMIaNe_7os"
      },
      "source": [
        "### 2. Suppression des caractères accentués\n",
        "**Description :** Cette fonction convertit les caractères accentués en leurs équivalents ASCII (ex: \"é\" devient \"e\"). Cela aide à normaliser les textes pour éviter les problèmes d'encodage.\\\n",
        "On pourra utiliser la librairie **unicodedata**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqOda0Gh-iNs"
      },
      "outputs": [],
      "source": [
        "import unicodedata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPTLyykLCx7L",
        "outputId": "ee7df657-4462-417a-ed55-aa02d8f5437b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           id                                               link  \\\n",
            "0  1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
            "1  1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
            "2  1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
            "3  1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
            "4  1773561338  https://twitter.com/realDonaldTrump/status/177...   \n",
            "\n",
            "                                             content                 date  \\\n",
            "0  Be sure to tune in and watch Donald Trump on L...  2009-05-04 20:54:25   \n",
            "1  Donald Trump will be appearing on The View tom...  2009-05-05 03:00:10   \n",
            "2  Donald Trump reads Top Ten Financial Tips on L...  2009-05-08 15:38:08   \n",
            "3  New Blog Post: Celebrity Apprentice Finale and...  2009-05-08 22:40:15   \n",
            "4  \"My persona will never be that of a wallflower...  2009-05-12 16:07:28   \n",
            "\n",
            "   retweets  favorites mentions hashtags  geo  \\\n",
            "0       500        868      NaN      NaN  NaN   \n",
            "1        33        273      NaN      NaN  NaN   \n",
            "2        12         18      NaN      NaN  NaN   \n",
            "3        11         24      NaN      NaN  NaN   \n",
            "4      1399       1965      NaN      NaN  NaN   \n",
            "\n",
            "                                     content_cleaned  \n",
            "0  Be sure to tune in and watch Donald Trump on L...  \n",
            "1  Donald Trump will be appearing on The View tom...  \n",
            "2  Donald Trump reads Top Ten Financial Tips on L...  \n",
            "3  New Blog Post: Celebrity Apprentice Finale and...  \n",
            "4  \"My persona will never be that of a wallflower...  \n"
          ]
        }
      ],
      "source": [
        "# Chemin du fichier CSV de mon dernier fichier enrégistré (fichier_nettoye_02)\n",
        "file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02.csv'\n",
        "\n",
        "# Charger le fichier CSV\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDf099ARZ1Sn"
      },
      "source": [
        "LA fonction pour supprimer les caractères accentués"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlHEtmEX_Zn0"
      },
      "outputs": [],
      "source": [
        "def remove_accented_chars(text):\n",
        "    \"\"\"\n",
        "    Remplace les caractères accentués par leurs équivalents sans accent.\n",
        "    \"\"\"\n",
        "    if pd.isna(text):  # Vérifie si la valeur est NaN\n",
        "        return text\n",
        "    # Normalise le texte en décomposant les caractères accentués\n",
        "    normalized_text = unicodedata.normalize('NFKD', str(text))\n",
        "    # Filtre pour ne garder que les caractères ASCII\n",
        "    ascii_text = normalized_text.encode('ascii', 'ignore').decode('ascii')\n",
        "    return ascii_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPx3lm4O-2yN",
        "outputId": "992fe58b-e165-4825-be1b-15ae51d1a187"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-141-890d799f849f>:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(remove_accented_chars)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           id                                               link  \\\n",
            "0  1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
            "1  1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
            "2  1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
            "3  1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
            "4  1773561338  https://twitter.com/realDonaldTrump/status/177...   \n",
            "\n",
            "                                             content                 date  \\\n",
            "0  Be sure to tune in and watch Donald Trump on L...  2009-05-04 20:54:25   \n",
            "1  Donald Trump will be appearing on The View tom...  2009-05-05 03:00:10   \n",
            "2  Donald Trump reads Top Ten Financial Tips on L...  2009-05-08 15:38:08   \n",
            "3  New Blog Post: Celebrity Apprentice Finale and...  2009-05-08 22:40:15   \n",
            "4  \"My persona will never be that of a wallflower...  2009-05-12 16:07:28   \n",
            "\n",
            "  retweets favorites mentions hashtags  geo  \\\n",
            "0      500       868      NaN      NaN  NaN   \n",
            "1       33       273      NaN      NaN  NaN   \n",
            "2       12        18      NaN      NaN  NaN   \n",
            "3       11        24      NaN      NaN  NaN   \n",
            "4     1399      1965      NaN      NaN  NaN   \n",
            "\n",
            "                                     content_cleaned  \n",
            "0  Be sure to tune in and watch Donald Trump on L...  \n",
            "1  Donald Trump will be appearing on The View tom...  \n",
            "2  Donald Trump reads Top Ten Financial Tips on L...  \n",
            "3  New Blog Post: Celebrity Apprentice Finale and...  \n",
            "4  \"My persona will never be that of a wallflower...  \n"
          ]
        }
      ],
      "source": [
        "# Appliquer la fonction à toutes les cellules du DataFrame\n",
        "df = df.applymap(remove_accented_chars)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZkRzgsN_IMX",
        "outputId": "5d860d31-a7ac-44c0-ca9f-e57b88b6c445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Les accents ont été supprimés de tout le fichier et le fichier a été sauvegardé.\n"
          ]
        }
      ],
      "source": [
        "# Chemin de sortie pour le fichier nettoyé\n",
        "output_file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_sans_accents.csv'\n",
        "\n",
        "# Sauvegarder le fichier\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Les accents ont été supprimés de tout le fichier et le fichier a été sauvegardé.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRqBP7X_NmfR"
      },
      "source": [
        "## Expansion des contractions\n",
        "\n",
        "### **Description** : Cette fonction à pour but de remplacer les mots contractés par leur forme non contractée.\n",
        "\n",
        "On pourra utiliser la librairie **contractions** ( ceci est une fonction simple essentielle pour avoir un code réutilisable). Ex : didn't = did not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K_eqxjrFCA0",
        "outputId": "7a3f3bdc-abbd-430b-b1fc-fc78c4c15e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.11/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions\n",
        "import contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFRdOhoJEaS7"
      },
      "outputs": [],
      "source": [
        "# Chemin du dernier fichier (fichier_nettoye_02_sans_accents.)\n",
        "file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_sans_accents.csv'\n",
        "\n",
        "# Charger le fichier CSV\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D45KLm-8Nl5J"
      },
      "outputs": [],
      "source": [
        "\n",
        "def expand_contractions(text):\n",
        "    \"\"\"\n",
        "    Remplace les abréviations courantes par leur signification complète.\n",
        "\n",
        "    Args:\n",
        "        text (str): Le texte contenant des contractions.\n",
        "\n",
        "    Returns:\n",
        "        str: Le texte avec les contractions remplacées.\n",
        "    \"\"\"\n",
        "    if pd.isna(text):  # Vérifie si la valeur est NaN\n",
        "        return text\n",
        "    # Utilise la bibliothèque contractions pour étendre les contractions\n",
        "    expanded_text = contractions.fix(str(text))\n",
        "    return expanded_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBOT4aORaJft"
      },
      "source": [
        "apllication de la fonction expand_contractions sur toutes les cellules du dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jwvqD2AEuYM",
        "outputId": "a6e79422-ac69-4002-a218-f7d37a872332"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-69-893245639824>:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(expand_contractions)\n"
          ]
        }
      ],
      "source": [
        "# Appliquer la fonction à toutes les cellules du DataFrame\n",
        "df = df.applymap(expand_contractions)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "#print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFrCEqn-aUWx"
      },
      "source": [
        "nous sauvegardons le fichier sans caractères accentués dans le fichier fichier_nettoye_02_sans_accents_expanded.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JML8M_EFVMR",
        "outputId": "1ee47aa3-aa9d-46b6-d098-7979b47be160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Les contractions ont été étendues et le fichier a été sauvegardé.\n"
          ]
        }
      ],
      "source": [
        "# Chemin de sortie pour le fichier modifié\n",
        "output_file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_sans_accents_expanded.csv'\n",
        "\n",
        "# Sauvegarder du nouveau fichier\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Les contractions ont été étendues et le fichier a été sauvegardé.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFRXZMRPAS9S"
      },
      "source": [
        "### 3. Lemmatisation avec spaCy\n",
        "**Description :** Cette fonction utilise la bibliothèque spaCy pour ramener chaque mot à sa forme de base (ex: \"running\" devient \"run\"). Elle aide à normaliser le vocabulaire et à améliorer les performances des modèles de NLP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHXPBgdNad7H"
      },
      "source": [
        "Installation des module nécéssaires\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn6l0A0BGBGy",
        "outputId": "22b8c74d-595e-4c58-83e0-74f1f896f6fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.11/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm  # Pour le modèle anglais\n",
        "!pip install contractions\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MemkblcSai2u"
      },
      "source": [
        "CHargement du fichier sans caractères accentués\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8vaMEPdGIU2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Charger un fichier CSV\n",
        "file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_sans_accents_expanded.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Afficher les premières lignes\n",
        "#print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EIbMyQRaoOi"
      },
      "source": [
        "Corps de la fonctions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPuBtDzWAXeY"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Fonction : spacy_lemmatize_text\n",
        "\n",
        "def spacy_lemmatize_text(text):\n",
        "    \"\"\"\n",
        "    Effectue la lemmatisation des mots du texte en utilisant spaCy.\n",
        "\n",
        "    Args:\n",
        "        text (str): Le texte à lemmatiser.\n",
        "\n",
        "    Returns:\n",
        "        str: Le texte avec les mots ramenés à leur forme de base.\n",
        "    \"\"\"\n",
        "    if pd.isna(text):  # Vérifie si la valeur est NaN\n",
        "        return text\n",
        "    # Tokenise et lemmatise le texte avec spaCy\n",
        "    doc = nlp(str(text))\n",
        "    lemmatized_text = \" \".join([token.lemma_ for token in doc])\n",
        "    return lemmatized_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9uXnLeZGmQI",
        "outputId": "7654aa26-aa40-478f-ad0d-0603afc270ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-145-951bd24cbae2>:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(spacy_lemmatize_text)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           id                                               link  \\\n",
            "0  1698308935  https://twitter.com/realDonaldTrump/status/169...   \n",
            "1  1701461182  https://twitter.com/realDonaldTrump/status/170...   \n",
            "2  1737479987  https://twitter.com/realDonaldTrump/status/173...   \n",
            "3  1741160716  https://twitter.com/realDonaldTrump/status/174...   \n",
            "4  1773561338  https://twitter.com/realdonaldtrump/status/177...   \n",
            "\n",
            "                                             content                     date  \\\n",
            "0  be sure to tune in and watch Donald Trump on L...  2009 - 05 - 04 20:54:25   \n",
            "1  Donald Trump will be appear on the view tomorr...  2009 - 05 - 05 03:00:10   \n",
            "2  Donald Trump read Top ten Financial Tips on La...  2009 - 05 - 08 15:38:08   \n",
            "3  New Blog Post : Celebrity Apprentice Finale an...  2009 - 05 - 08 22:40:15   \n",
            "4  \" my persona will never be that of a wallflowe...  2009 - 05 - 12 16:07:28   \n",
            "\n",
            "  retweets favorites mentions hashtags  geo  \\\n",
            "0      500       868      NaN      NaN  NaN   \n",
            "1       33       273      NaN      NaN  NaN   \n",
            "2       12        18      NaN      NaN  NaN   \n",
            "3       11        24      NaN      NaN  NaN   \n",
            "4     1399      1965      NaN      NaN  NaN   \n",
            "\n",
            "                                     content_cleaned  \n",
            "0  be sure to tune in and watch Donald Trump on L...  \n",
            "1  Donald Trump will be appear on the view tomorr...  \n",
            "2  Donald Trump read Top ten Financial Tips on La...  \n",
            "3  New Blog Post : Celebrity Apprentice Finale an...  \n",
            "4  \" my persona will never be that of a wallflowe...  \n"
          ]
        }
      ],
      "source": [
        "# Appliquer la fonction à toutes les cellules du DataFrame\n",
        "df = df.applymap(spacy_lemmatize_text)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4ygFVPwawKG"
      },
      "source": [
        "sauvegarde dans un fichier fichier_nettoye_02_new\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSexZDp_GwrH",
        "outputId": "82204dfe-6f56-4166-edbd-fff4b8e2ac7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La lemmatisation a été effectuée et le fichier a été sauvegardé.\n"
          ]
        }
      ],
      "source": [
        "# Chemin de sortie pour le fichier modifié\n",
        "output_file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new.csv'\n",
        "\n",
        "# Sauvegarder le fichier\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"La lemmatisation a été effectuée et le fichier a été sauvegardé.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M09A2FmkAdTu"
      },
      "source": [
        "### 4. Stemming avec NLTK\n",
        "**Description :** Cette fonction applique un algorithme de \"stemming\", qui réduit les mots à leur racine (ex: \"playing\" devient \"play\"). Contrairement à la lemmatisation, il ne garantit pas toujours un mot existant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD-eFNufIbAW",
        "outputId": "c22c16b9-150e-446e-e5b1-7d3e543362e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "# Installer NLTK\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BSG8e1QId-D",
        "outputId": "0f576cb7-b26e-4d85-f561-806aeb9f94cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "# Importer NLTK et télécharger les ressources\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmU2qwxCcsmE"
      },
      "source": [
        "Nous allons charger le fichier fichier_nettoye_02_new.csv que nous avons créé précédemment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCUwQwwTIkyJ"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new.csv'\n",
        "\n",
        "# Charger le fichier CSV\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "d7VEZD25Rtk7",
        "outputId": "5e3511cd-08a4-4372-bc14-e0b16f69700d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Initialiser un stemmer (PorterStemmer ou SnowballStemmer)\\nstemmer = PorterStemmer()  # Ou SnowballStemmer('english')\\n\\n# Appliquer la fonction à toutes les cellules du DataFrame\\ndf = df.applymap(lambda x: simple_stemming(x, stemmer))\\n\\n# Afficher les premières lignes pour vérifier\\nprint(df.head())\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download the 'punkt_tab' resource\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new.csv'\n",
        "\n",
        "# Charger le fichier CSV\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "# Fonction : simple_stemming\n",
        "\n",
        "def simple_stemming(text, stemmer):\n",
        "    \"\"\"\n",
        "    Réduit les mots à leur racine en utilisant un algorithme de stemming.\n",
        "    \"\"\"\n",
        "    if pd.isna(text):  # Vérifie si la valeur est NaN\n",
        "        return text\n",
        "    # Tokeniser le texte en mots\n",
        "    words = word_tokenize(str(text))\n",
        "    # Appliquer le stemming à chaque mot\n",
        "    stemmed_words = [stemmer.stem(word) for word in words]\n",
        "    # Reconstruire le texte\n",
        "    stemmed_text = \" \".join(stemmed_words)\n",
        "    return stemmed_text\n",
        "\n",
        "\"\"\"\n",
        "# Initialiser un stemmer (PorterStemmer ou SnowballStemmer)\n",
        "stemmer = PorterStemmer()  # Ou SnowballStemmer('english')\n",
        "\n",
        "# Appliquer la fonction à toutes les cellules du DataFrame\n",
        "df = df.applymap(lambda x: simple_stemming(x, stemmer))\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MUP83hpdiNj"
      },
      "source": [
        "Nous allons utiliser applymap pour appliquer la fonction simple_stemming à toutes les cellules du DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC1isc3bdKIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207d1322-d42b-4ed7-9205-55f9818d1dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-151-ade5c75621d2>:5: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: simple_stemming(x, stemmer))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           id                                               link  \\\n",
            "0  1698308935  http : //twitter.com/realdonaldtrump/status/16...   \n",
            "1  1701461182  http : //twitter.com/realdonaldtrump/status/17...   \n",
            "2  1737479987  http : //twitter.com/realdonaldtrump/status/17...   \n",
            "3  1741160716  http : //twitter.com/realdonaldtrump/status/17...   \n",
            "4  1773561338  http : //twitter.com/realdonaldtrump/status/17...   \n",
            "\n",
            "                                             content                     date  \\\n",
            "0  be sure to tune in and watch donald trump on l...  2009 - 05 - 04 20:54:25   \n",
            "1  donald trump will be appear on the view tomorr...  2009 - 05 - 05 03:00:10   \n",
            "2  donald trump read top ten financi tip on late ...  2009 - 05 - 08 15:38:08   \n",
            "3  new blog post : celebr apprentic final and les...  2009 - 05 - 08 22:40:15   \n",
            "4  `` my persona will never be that of a wallflow...  2009 - 05 - 12 16:07:28   \n",
            "\n",
            "  retweets favorites mentions hashtags  geo  \\\n",
            "0      500       868      NaN      NaN  NaN   \n",
            "1       33       273      NaN      NaN  NaN   \n",
            "2       12        18      NaN      NaN  NaN   \n",
            "3       11        24      NaN      NaN  NaN   \n",
            "4     1399      1965      NaN      NaN  NaN   \n",
            "\n",
            "                                     content_cleaned  \n",
            "0  be sure to tune in and watch donald trump on l...  \n",
            "1  donald trump will be appear on the view tomorr...  \n",
            "2  donald trump read top ten financi tip on late ...  \n",
            "3  new blog post : celebr apprentic final and les...  \n",
            "4  `` my persona will never be that of a wallflow...  \n"
          ]
        }
      ],
      "source": [
        "# Initialiser un stemmer (PorterStemmer ou SnowballStemmer)\n",
        "stemmer = PorterStemmer()  # Ou SnowballStemmer('english')\n",
        "\n",
        "# Appliquer la fonction à toutes les cellules du DataFrame\n",
        "df = df.applymap(lambda x: simple_stemming(x, stemmer))\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPivPfUjdaAN"
      },
      "source": [
        "Nous allons sauvegarder le DataFrame modifié dans un nouveau fichier 'fichier_nettoye_02_new_01.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u07Ug3UBJqSO",
        "outputId": "70879580-fb7f-4045-b34f-695f1d3fd36c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Le stemming a été effectué et le fichier a été sauvegardé.\n"
          ]
        }
      ],
      "source": [
        "# Chemin de sortie pour le fichier modifié\n",
        "output_file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new_01.csv'\n",
        "\n",
        "# Sauvegarder le fichier\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Le stemming a été effectué et le fichier a été sauvegardé.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "407vnwVcAhJh"
      },
      "source": [
        "### 5. Suppression des caractères spéciaux\n",
        "**Description :** Cette fonction supprime tous les caractères non alphabétiques ou non numériques selon le besoin. Elle permet d'éliminer les symboles inutiles qui peuvent perturber l'analyse.\n",
        "\n",
        "On utilisera les expressions régulières"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHQ5H5bSdsEG"
      },
      "source": [
        "Nous allons charger le fichier fichier_nettoye_02_new_01.csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ3HhuyoJ-Xd",
        "outputId": "8712d4c5-9837-4db7-c2c3-5badc5c6a6f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           id                                               link  \\\n",
            "0  1698308935  http : //twitter.com/realdonaldtrump/status/16...   \n",
            "1  1701461182  http : //twitter.com/realdonaldtrump/status/17...   \n",
            "2  1737479987  http : //twitter.com/realdonaldtrump/status/17...   \n",
            "3  1741160716  http : //twitter.com/realdonaldtrump/status/17...   \n",
            "4  1773561338  http : //twitter.com/realdonaldtrump/status/17...   \n",
            "\n",
            "                                             content                     date  \\\n",
            "0  be sure to tune in and watch donald trump on l...  2009 - 05 - 04 20:54:25   \n",
            "1  donald trump will be appear on the view tomorr...  2009 - 05 - 05 03:00:10   \n",
            "2  donald trump read top ten financi tip on late ...  2009 - 05 - 08 15:38:08   \n",
            "3  new blog post : celebr apprentic final and les...  2009 - 05 - 08 22:40:15   \n",
            "4  `` my persona will never be that of a wallflow...  2009 - 05 - 12 16:07:28   \n",
            "\n",
            "   retweets  favorites mentions hashtags  geo  \\\n",
            "0       500        868      NaN      NaN  NaN   \n",
            "1        33        273      NaN      NaN  NaN   \n",
            "2        12         18      NaN      NaN  NaN   \n",
            "3        11         24      NaN      NaN  NaN   \n",
            "4      1399       1965      NaN      NaN  NaN   \n",
            "\n",
            "                                     content_cleaned  \n",
            "0  be sure to tune in and watch donald trump on l...  \n",
            "1  donald trump will be appear on the view tomorr...  \n",
            "2  donald trump read top ten financi tip on late ...  \n",
            "3  new blog post : celebr apprentic final and les...  \n",
            "4  `` my persona will never be that of a wallflow...  \n"
          ]
        }
      ],
      "source": [
        "# Chemin du fichier\n",
        "file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new_01.csv'\n",
        "\n",
        "# Charger le fichier CSV\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGg5Biy2dv8O"
      },
      "source": [
        "corps de la fonction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1Y5qY1MBGLq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Fonction : remove_special_characters\n",
        "\n",
        "def remove_special_characters(text, remove_digits):\n",
        "    \"\"\"\n",
        "    Supprime les caractères spéciaux du texte tout en conservant les chiffres si nécessaire.\n",
        "    \"\"\"\n",
        "    if pd.isna(text):  # Vérifie si la valeur est NaN\n",
        "        return text\n",
        "    # Définir le motif en fonction de remove_digits\n",
        "    if remove_digits:\n",
        "        pattern = r'[^a-zA-Z\\s]'  # Conserve uniquement les lettres et les espaces\n",
        "    else:\n",
        "        pattern = r'[^a-zA-Z0-9\\s]'  # Conserve les lettres, les chiffres et les espaces\n",
        "    # Supprimer les caractères spéciaux\n",
        "    cleaned_text = re.sub(pattern, '', str(text))\n",
        "    return cleaned_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO0C6Rz-bnj1"
      },
      "source": [
        "Nous allons utiliser applymap pour appliquer la fonction remove_special_characters à toutes les cellules du DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoShEylvKH6V",
        "outputId": "936749b1-9a6a-4c9c-c969-16444b0b1b40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-155-ea678f2f0d22>:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: remove_special_characters(x, remove_digits=False))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           id                                             link  \\\n",
            "0  1698308935  http  twittercomrealdonaldtrumpstatus1698308935   \n",
            "1  1701461182  http  twittercomrealdonaldtrumpstatus1701461182   \n",
            "2  1737479987  http  twittercomrealdonaldtrumpstatus1737479987   \n",
            "3  1741160716  http  twittercomrealdonaldtrumpstatus1741160716   \n",
            "4  1773561338  http  twittercomrealdonaldtrumpstatus1773561338   \n",
            "\n",
            "                                             content                 date  \\\n",
            "0  be sure to tune in and watch donald trump on l...  2009  05  04 205425   \n",
            "1  donald trump will be appear on the view tomorr...  2009  05  05 030010   \n",
            "2  donald trump read top ten financi tip on late ...  2009  05  08 153808   \n",
            "3  new blog post  celebr apprentic final and less...  2009  05  08 224015   \n",
            "4   my persona will never be that of a wallflow  ...  2009  05  12 160728   \n",
            "\n",
            "  retweets favorites mentions hashtags  geo  \\\n",
            "0      500       868      NaN      NaN  NaN   \n",
            "1       33       273      NaN      NaN  NaN   \n",
            "2       12        18      NaN      NaN  NaN   \n",
            "3       11        24      NaN      NaN  NaN   \n",
            "4     1399      1965      NaN      NaN  NaN   \n",
            "\n",
            "                                     content_cleaned  \n",
            "0  be sure to tune in and watch donald trump on l...  \n",
            "1  donald trump will be appear on the view tomorr...  \n",
            "2  donald trump read top ten financi tip on late ...  \n",
            "3  new blog post  celebr apprentic final and less...  \n",
            "4   my persona will never be that of a wallflow  ...  \n"
          ]
        }
      ],
      "source": [
        "# Appliquer la fonction à toutes les cellules du DataFrame\n",
        "# Ici, nous conservons les chiffres (remove_digits=False)\n",
        "df = df.applymap(lambda x: remove_special_characters(x, remove_digits=False))\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE3ZDMXMbbQb"
      },
      "source": [
        "exportation dans le fichier 'fichier_nettoye_02_new_02.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIeTlujgKLIQ",
        "outputId": "161c4b07-8459-44a9-861d-cae9aeee4d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les caractères spéciaux ont été supprimés et le fichier a été sauvegardé sous : /content/drive/My Drive/data mining/fichier_nettoye_02_new_02.csv\n"
          ]
        }
      ],
      "source": [
        "# Chemin de sortie pour le fichier modifié\n",
        "output_file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new_02.csv'\n",
        "\n",
        "# Sauvegarder le fichier\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Les caractères spéciaux ont été supprimés et le fichier a été sauvegardé sous :\", output_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7M5iMFVBJhh"
      },
      "source": [
        "### 6. Suppression des stopwords\n",
        "**Description :** Cette fonction enlève les mots les plus fréquents d'une langue qui n'apportent pas de sens (ex: \"the\", \"and\", \"is\" en anglais). Cela réduit la taille du texte et améliore la pertinence des analyses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znudRyhueWjc"
      },
      "source": [
        "NLTK est une bibliothèque populaire pour le traitement du langage naturel. Nous devons d'abord l'importer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbXL1HTmLCr2",
        "outputId": "d14218b0-b9be-4c1b-a5ee-961146656e52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzkDaOvAd9re"
      },
      "source": [
        "chargement du fichier 'fichier_nettoye_02_new_02.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wIKQVa1LGln"
      },
      "outputs": [],
      "source": [
        "# Chemin du fichier\n",
        "file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new_02.csv'\n",
        "\n",
        "# Charger le fichier CSV\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "#print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qraeclTWelQi"
      },
      "source": [
        "La fonction utilise la liste des stopwords de NLTK pour supprimer les mots vides du texte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGVcOcK1BNM3"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text, is_lower_case=False, stopwords_set=None):\n",
        "    \"\"\"\n",
        "    Supprime les mots vides (stopwords) du texte.\n",
        "\n",
        "    Args:\n",
        "        text (str): Le texte à traiter.\n",
        "        is_lower_case (bool): Si True, convertit le texte en minuscules avant de supprimer les stopwords.\n",
        "        stopwords_set (set): Un ensemble de stopwords à supprimer. Si None, utilise les stopwords par défaut de NLTK.\n",
        "\n",
        "    Returns:\n",
        "        str: Le texte sans les stopwords.\n",
        "    \"\"\"\n",
        "    if pd.isna(text):  # Vérifie si la valeur est NaN\n",
        "        return text\n",
        "    # Convertir le texte en minuscules si nécessaire\n",
        "    if is_lower_case:\n",
        "        text = text.lower()\n",
        "    # Tokeniser le texte en mots\n",
        "    words = word_tokenize(str(text))\n",
        "    # Utiliser les stopwords par défaut de NLTK si aucun ensemble n'est fourni\n",
        "    if stopwords_set is None:\n",
        "        stopwords_set = set(stopwords.words('english'))  # Pour l'anglais\n",
        "    # Supprimer les stopwords\n",
        "    filtered_words = [word for word in words if word.lower() not in stopwords_set]\n",
        "    # Reconstruire le texte\n",
        "    filtered_text = \" \".join(filtered_words)\n",
        "    return filtered_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9sSZcRmep2q"
      },
      "source": [
        "Nous allons utiliser applymap pour appliquer la fonction remove_stopwords à toutes les cellules du DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAOhZQBSLbCO",
        "outputId": "4571d24c-9d4b-44d2-ac39-b700ed15283b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-160-9d65372e64b6>:3: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: remove_stopwords(x, is_lower_case=False, stopwords_set=None)) # Change 'stopwords' to 'stopwords_set'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           id                                            link  \\\n",
            "0  1698308935  http twittercomrealdonaldtrumpstatus1698308935   \n",
            "1  1701461182  http twittercomrealdonaldtrumpstatus1701461182   \n",
            "2  1737479987  http twittercomrealdonaldtrumpstatus1737479987   \n",
            "3  1741160716  http twittercomrealdonaldtrumpstatus1741160716   \n",
            "4  1773561338  http twittercomrealdonaldtrumpstatus1773561338   \n",
            "\n",
            "                                             content               date  \\\n",
            "0  sure tune watch donald trump late night david ...  2009 05 04 205425   \n",
            "1  donald trump appear view tomorrow morn discuss...  2009 05 05 030010   \n",
            "2  donald trump read top ten financi tip late sho...  2009 05 08 153808   \n",
            "3  new blog post celebr apprentic final lesson le...  2009 05 08 224015   \n",
            "4  persona never wallflow rather build wall cle d...  2009 05 12 160728   \n",
            "\n",
            "  retweets favorites mentions hashtags  geo  \\\n",
            "0      500       868      NaN      NaN  NaN   \n",
            "1       33       273      NaN      NaN  NaN   \n",
            "2       12        18      NaN      NaN  NaN   \n",
            "3       11        24      NaN      NaN  NaN   \n",
            "4     1399      1965      NaN      NaN  NaN   \n",
            "\n",
            "                                     content_cleaned  \n",
            "0  sure tune watch donald trump late night david ...  \n",
            "1  donald trump appear view tomorrow morn discuss...  \n",
            "2  donald trump read top ten financi tip late sho...  \n",
            "3  new blog post celebr apprentic final lesson le...  \n",
            "4  persona never wallflow rather build wall cle d...  \n"
          ]
        }
      ],
      "source": [
        "# Appliquer la fonction à toutes les cellules du DataFrame\n",
        "# Ici, nous ne convertissons pas en minuscules (is_lower_case=False) et utilisons les stopwords par défaut\n",
        "df = df.applymap(lambda x: remove_stopwords(x, is_lower_case=False, stopwords_set=None)) # Change 'stopwords' to 'stopwords_set'\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lckQ-EbkevmD"
      },
      "source": [
        "Sauvegarde dans le fichier 'fichier_nettoye_02_new_03.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW77AaLILeqZ",
        "outputId": "4af42ad7-83dd-41dd-f0b5-a15d1539bc4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les stopwords ont été supprimés et le fichier a été sauvegardé sous : /content/drive/My Drive/data mining/fichier_nettoye_02_new_03.csv\n"
          ]
        }
      ],
      "source": [
        "# Chemin de sortie pour le fichier modifié\n",
        "output_file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new_03.csv'\n",
        "\n",
        "# Sauvegarder le fichier\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Les stopwords ont été supprimés et le fichier a été sauvegardé sous :\", output_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh1-98V8BRjP"
      },
      "source": [
        "### 7. Conversion des emojis ou emoticons en texte\n",
        "**Description :** Les emojis ou emoticons peuvent nous donner une signification supplémentaire. Cette fonction transforme les emojis en mots correspondants (ex: \"😂\" devient \"joy face\"). Cela permet de mieux analyser leur signification dans les textes. Vous pouvez utiliser la librairie **emoji**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-v30d68Lw8m",
        "outputId": "fa9b3e5e-e644-4d9b-ba88-4df4637f2d0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.11/dist-packages (2.14.1)\n"
          ]
        }
      ],
      "source": [
        "# Installer la bibliothèque emoji\n",
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THTgdXL-e-OE"
      },
      "source": [
        "Nous devons installer la bibliothèque emoji pour gérer les emojis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4gvCk16LyZe"
      },
      "outputs": [],
      "source": [
        "import emoji #importation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozfmwAUTfFv6"
      },
      "source": [
        "Nous allons charger le fichier fichier_nettoye_02_new_03.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBvCENmKL4es"
      },
      "outputs": [],
      "source": [
        "# Chemin du fichier\n",
        "file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new_03.csv'\n",
        "\n",
        "# Charger le fichier CSV\n",
        "df = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwLRE5w_fJAE"
      },
      "source": [
        "La fonction utilise la bibliothèque emoji pour convertir les emojis en texte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZqzKWwp_BVBg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Fonction : convert_emojis\n",
        "\n",
        "def convert_emojis(text):\n",
        "    \"\"\"\n",
        "    Convertit les emojis en texte explicite.\n",
        "    \"\"\"\n",
        "    if pd.isna(text):  # Vérifie si la valeur est NaN\n",
        "        return text\n",
        "    # Convertir les emojis en texte\n",
        "    converted_text = emoji.demojize(str(text), delimiters=(\" \", \" \"))\n",
        "    return converted_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2i1Od7WPC40"
      },
      "source": [
        "Nous allons convertir les emojis de notre fichier \"fichier_nettoye_02_new_03.csv\" ensuite convertir les emoticons\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGM4Y4_QPBy6",
        "outputId": "e920c082-0588-4953-c4ee-53fdb5e1652e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-166-c465e0d6e9b4>:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(convert_emojis)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           id                                            link  \\\n",
            "0  1698308935  http twittercomrealdonaldtrumpstatus1698308935   \n",
            "1  1701461182  http twittercomrealdonaldtrumpstatus1701461182   \n",
            "2  1737479987  http twittercomrealdonaldtrumpstatus1737479987   \n",
            "3  1741160716  http twittercomrealdonaldtrumpstatus1741160716   \n",
            "4  1773561338  http twittercomrealdonaldtrumpstatus1773561338   \n",
            "\n",
            "                                             content               date  \\\n",
            "0  sure tune watch donald trump late night david ...  2009 05 04 205425   \n",
            "1  donald trump appear view tomorrow morn discuss...  2009 05 05 030010   \n",
            "2  donald trump read top ten financi tip late sho...  2009 05 08 153808   \n",
            "3  new blog post celebr apprentic final lesson le...  2009 05 08 224015   \n",
            "4  persona never wallflow rather build wall cle d...  2009 05 12 160728   \n",
            "\n",
            "  retweets favorites mentions hashtags  geo  \\\n",
            "0      500       868      NaN      NaN  NaN   \n",
            "1       33       273      NaN      NaN  NaN   \n",
            "2       12        18      NaN      NaN  NaN   \n",
            "3       11        24      NaN      NaN  NaN   \n",
            "4     1399      1965      NaN      NaN  NaN   \n",
            "\n",
            "                                     content_cleaned  \n",
            "0  sure tune watch donald trump late night david ...  \n",
            "1  donald trump appear view tomorrow morn discuss...  \n",
            "2  donald trump read top ten financi tip late sho...  \n",
            "3  new blog post celebr apprentic final lesson le...  \n",
            "4  persona never wallflow rather build wall cle d...  \n"
          ]
        }
      ],
      "source": [
        "# Appliquer la fonction à toutes les cellules du DataFrame\n",
        "df = df.applymap(convert_emojis)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK_zp0tRTluB"
      },
      "outputs": [],
      "source": [
        "# Fonction : convert_emoticons\n",
        "\n",
        "def convert_emoticons(text):\n",
        "    \"\"\"\n",
        "    Convertit les emoticons en texte explicite.\n",
        "    \"\"\"\n",
        "    if pd.isna(text):  # Vérifie si la valeur est NaN\n",
        "        return text\n",
        "\n",
        "    # Dictionnaire de correspondance entre emoticons et texte\n",
        "    emoticon_dict = {\n",
        "        \":)\": \"smiley face\",\n",
        "        \":(\": \"sad face\",\n",
        "        \":D\": \"big smile\",\n",
        "        \":P\": \"tongue out\",\n",
        "        \";)\": \"winking face\",\n",
        "        \":'(\": \"crying face\",\n",
        "        \"<3\": \"heart\",\n",
        "        \"</3\": \"broken heart\",\n",
        "        \":-|\": \"neutral face\",\n",
        "        \":-/\": \"confused face\",\n",
        "        \":-O\": \"surprised face\",\n",
        "        \":-*\": \"kiss face\",\n",
        "        \">:(\": \"angry face\",\n",
        "        \"O:-)\": \"angel face\",\n",
        "        \":-@\": \"screaming face\",\n",
        "        \":-$\": \"confused face\",\n",
        "        \":-!\": \"confused face\",\n",
        "        \":-&\": \"speechless face\",\n",
        "        \":-%\": \"confused face\",\n",
        "        \":-S\": \"confused face\",\n",
        "        \":-X\": \"sealed lips\",\n",
        "        \":-C\": \"very sad face\",\n",
        "        \":-[\": \"angry face\",\n",
        "        \":-]\": \"smiling face\",\n",
        "        \":-\\\\\": \"confused face\",\n",
        "        \":-=\": \"confused face\",\n",
        "        \":-Þ\": \"tongue out\",\n",
        "        \":-b\": \"tongue out\",\n",
        "        \":-p\": \"tongue out\",\n",
        "        \":-d\": \"tongue out\",\n",
        "        \":-o\": \"surprised face\",\n",
        "        \":-3\": \"smiling face\",\n",
        "    }\n",
        "\n",
        "    # Remplacer les emoticons par leur description\n",
        "    for emoticon, description in emoticon_dict.items():\n",
        "        text = text.replace(emoticon, description)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaL4F75NfQK2"
      },
      "source": [
        "Appliquer la fonction pour supprimer les emojis dans toutes la cellules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHWFOBugO310",
        "outputId": "6e17a45f-6c8d-40c5-b484-24a6823b5530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-168-e22a14535eb5>:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(convert_emoticons)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           id                                            link  \\\n",
            "0  1698308935  http twittercomrealdonaldtrumpstatus1698308935   \n",
            "1  1701461182  http twittercomrealdonaldtrumpstatus1701461182   \n",
            "2  1737479987  http twittercomrealdonaldtrumpstatus1737479987   \n",
            "3  1741160716  http twittercomrealdonaldtrumpstatus1741160716   \n",
            "4  1773561338  http twittercomrealdonaldtrumpstatus1773561338   \n",
            "\n",
            "                                             content               date  \\\n",
            "0  sure tune watch donald trump late night david ...  2009 05 04 205425   \n",
            "1  donald trump appear view tomorrow morn discuss...  2009 05 05 030010   \n",
            "2  donald trump read top ten financi tip late sho...  2009 05 08 153808   \n",
            "3  new blog post celebr apprentic final lesson le...  2009 05 08 224015   \n",
            "4  persona never wallflow rather build wall cle d...  2009 05 12 160728   \n",
            "\n",
            "  retweets favorites mentions hashtags  geo  \\\n",
            "0      500       868      NaN      NaN  NaN   \n",
            "1       33       273      NaN      NaN  NaN   \n",
            "2       12        18      NaN      NaN  NaN   \n",
            "3       11        24      NaN      NaN  NaN   \n",
            "4     1399      1965      NaN      NaN  NaN   \n",
            "\n",
            "                                     content_cleaned  \n",
            "0  sure tune watch donald trump late night david ...  \n",
            "1  donald trump appear view tomorrow morn discuss...  \n",
            "2  donald trump read top ten financi tip late sho...  \n",
            "3  new blog post celebr apprentic final lesson le...  \n",
            "4  persona never wallflow rather build wall cle d...  \n"
          ]
        }
      ],
      "source": [
        "# Appliquer la fonction à toutes les cellules du DataFrame\n",
        "df = df.applymap(convert_emoticons)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHfKH3ptPXwq"
      },
      "source": [
        "NOus sauvegardons un fichier r_nettoye_02_new_04.csv dans lequel les emoji et emoticons sont convertis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdeQWNRAPXBY",
        "outputId": "8fa78c47-de0b-47c3-c33a-e66b76d69f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les emojis et emoticons ont été convertis et le fichier a été sauvegardé sous : /content/drive/My Drive/data mining/fichier_nettoye_02_new_04.csv\n"
          ]
        }
      ],
      "source": [
        "# Chemin de sortie pour le fichier modifié\n",
        "output_file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new_04.csv'\n",
        "\n",
        "# Sauvegarder le fichier\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Les emojis et emoticons ont été convertis et le fichier a été sauvegardé sous :\", output_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2ryr4zABeXB"
      },
      "source": [
        "### 8. Suppression des emojis\n",
        "**Description :** Cette fonction supprime entièrement les emojis du texte. Utile si l'on veut nettoyer les données et garder uniquement du texte brut."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28-wuBUsPtzY"
      },
      "source": [
        "Vu qu'il n'ya pas d'émojis dans notre fichier r_nettoye_02_new_04.csv nous allons utiliser le fichier fichier_nettoye_02_new_03.csv dans lequel nous avons supprimer les stopwords sans avoir touché aux emojis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHkCLnb8QkGW"
      },
      "outputs": [],
      "source": [
        "# Chemin du fichier\n",
        "file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new_03.csv'\n",
        "\n",
        "# Charger le fichier CSV\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "#print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jcGNcY8Q0au"
      },
      "source": [
        "La fonction utilise une expression régulière pour supprimer tous les emojis du texte. Les emojis sont des caractères Unicode, donc nous allons utiliser un motif qui correspond à ces caractères."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJk2DPPcBiQ3"
      },
      "outputs": [],
      "source": [
        "def remove_emoji(text):\n",
        "    \"\"\"\n",
        "    Supprime tous les emojis présents dans le texte.\n",
        "\n",
        "    Args:\n",
        "        text (str): Le texte contenant des emojis.\n",
        "\n",
        "    Returns:\n",
        "        str: Le texte sans emojis.\n",
        "    \"\"\"\n",
        "    if pd.isna(text):  # Vérifie si la valeur est NaN\n",
        "        return text\n",
        "\n",
        "    # Expression régulière pour détecter les emojis\n",
        "    emoji_pattern = re.compile(\n",
        "        \"[\"\n",
        "        \"\\U0001F600-\\U0001F64F\"  # Emojis de visages\n",
        "        \"\\U0001F300-\\U0001F5FF\"  # Symboles et pictogrammes\n",
        "        \"\\U0001F680-\\U0001F6FF\"  # Transports et cartes\n",
        "        \"\\U0001F700-\\U0001F77F\"  # Alchimie\n",
        "        \"\\U0001F780-\\U0001F7FF\"  # Formes géométriques\n",
        "        \"\\U0001F800-\\U0001F8FF\"  # Symboles supplémentaires\n",
        "        \"\\U0001F900-\\U0001F9FF\"  # Emojis supplémentaires\n",
        "        \"\\U0001FA00-\\U0001FA6F\"  # Jeux\n",
        "        \"\\U0001FA70-\\U0001FAFF\"  # Symboles supplémentaires\n",
        "        \"\\U00002702-\\U000027B0\"  # Symboles divers\n",
        "        \"\\U000024C2-\\U0001F251\"  # Enclosed characters\n",
        "        \"]+\", flags=re.UNICODE)\n",
        "\n",
        "    # Supprimer les emojis du texte\n",
        "    cleaned_text = emoji_pattern.sub(r'', str(text))\n",
        "    return cleaned_text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cmcn9RLnQ5ZT"
      },
      "source": [
        "Nous allons utiliser applymap pour appliquer la fonction remove_emoji à toutes les cellules du DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDQQxFHhQ4mz",
        "outputId": "b3b102f1-8d3a-4a9b-d6a6-29f6d828634f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-174-1a5bcbef938e>:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(remove_emoji)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           id                                            link  \\\n",
            "0  1698308935  http twittercomrealdonaldtrumpstatus1698308935   \n",
            "1  1701461182  http twittercomrealdonaldtrumpstatus1701461182   \n",
            "2  1737479987  http twittercomrealdonaldtrumpstatus1737479987   \n",
            "3  1741160716  http twittercomrealdonaldtrumpstatus1741160716   \n",
            "4  1773561338  http twittercomrealdonaldtrumpstatus1773561338   \n",
            "\n",
            "                                             content               date  \\\n",
            "0  sure tune watch donald trump late night david ...  2009 05 04 205425   \n",
            "1  donald trump appear view tomorrow morn discuss...  2009 05 05 030010   \n",
            "2  donald trump read top ten financi tip late sho...  2009 05 08 153808   \n",
            "3  new blog post celebr apprentic final lesson le...  2009 05 08 224015   \n",
            "4  persona never wallflow rather build wall cle d...  2009 05 12 160728   \n",
            "\n",
            "  retweets favorites mentions hashtags  geo  \\\n",
            "0      500       868      NaN      NaN  NaN   \n",
            "1       33       273      NaN      NaN  NaN   \n",
            "2       12        18      NaN      NaN  NaN   \n",
            "3       11        24      NaN      NaN  NaN   \n",
            "4     1399      1965      NaN      NaN  NaN   \n",
            "\n",
            "                                     content_cleaned  \n",
            "0  sure tune watch donald trump late night david ...  \n",
            "1  donald trump appear view tomorrow morn discuss...  \n",
            "2  donald trump read top ten financi tip late sho...  \n",
            "3  new blog post celebr apprentic final lesson le...  \n",
            "4  persona never wallflow rather build wall cle d...  \n"
          ]
        }
      ],
      "source": [
        "# Appliquer la fonction à toutes les cellules du DataFrame\n",
        "df = df.applymap(remove_emoji)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puTGbqBDRBbw"
      },
      "source": [
        "Nous allons sauvegarder le DataFrame modifié dans un nouveau fichier nommé fichier_nettoye_02_new_05.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "pnVNwYYJQ_Xz",
        "outputId": "2ceb5155-fd75-4956-a1ac-0f7bf39d2363"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les emojis ont été supprimés et le fichier a été sauvegardé sous : /content/drive/My Drive/data mining/fichier_nettoye_02_new_05.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                            link  \\\n",
              "0  1698308935  http twittercomrealdonaldtrumpstatus1698308935   \n",
              "1  1701461182  http twittercomrealdonaldtrumpstatus1701461182   \n",
              "2  1737479987  http twittercomrealdonaldtrumpstatus1737479987   \n",
              "3  1741160716  http twittercomrealdonaldtrumpstatus1741160716   \n",
              "4  1773561338  http twittercomrealdonaldtrumpstatus1773561338   \n",
              "\n",
              "                                             content               date  \\\n",
              "0  sure tune watch donald trump late night david ...  2009 05 04 205425   \n",
              "1  donald trump appear view tomorrow morn discuss...  2009 05 05 030010   \n",
              "2  donald trump read top ten financi tip late sho...  2009 05 08 153808   \n",
              "3  new blog post celebr apprentic final lesson le...  2009 05 08 224015   \n",
              "4  persona never wallflow rather build wall cle d...  2009 05 12 160728   \n",
              "\n",
              "   retweets  favorites mentions hashtags  geo  \\\n",
              "0       500        868      NaN      NaN  NaN   \n",
              "1        33        273      NaN      NaN  NaN   \n",
              "2        12         18      NaN      NaN  NaN   \n",
              "3        11         24      NaN      NaN  NaN   \n",
              "4      1399       1965      NaN      NaN  NaN   \n",
              "\n",
              "                                     content_cleaned  \n",
              "0  sure tune watch donald trump late night david ...  \n",
              "1  donald trump appear view tomorrow morn discuss...  \n",
              "2  donald trump read top ten financi tip late sho...  \n",
              "3  new blog post celebr apprentic final lesson le...  \n",
              "4  persona never wallflow rather build wall cle d...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-242691fa-d0e3-46a2-aa37-6d0d697552f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>link</th>\n",
              "      <th>content</th>\n",
              "      <th>date</th>\n",
              "      <th>retweets</th>\n",
              "      <th>favorites</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>geo</th>\n",
              "      <th>content_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1698308935</td>\n",
              "      <td>http twittercomrealdonaldtrumpstatus1698308935</td>\n",
              "      <td>sure tune watch donald trump late night david ...</td>\n",
              "      <td>2009 05 04 205425</td>\n",
              "      <td>500</td>\n",
              "      <td>868</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sure tune watch donald trump late night david ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1701461182</td>\n",
              "      <td>http twittercomrealdonaldtrumpstatus1701461182</td>\n",
              "      <td>donald trump appear view tomorrow morn discuss...</td>\n",
              "      <td>2009 05 05 030010</td>\n",
              "      <td>33</td>\n",
              "      <td>273</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>donald trump appear view tomorrow morn discuss...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1737479987</td>\n",
              "      <td>http twittercomrealdonaldtrumpstatus1737479987</td>\n",
              "      <td>donald trump read top ten financi tip late sho...</td>\n",
              "      <td>2009 05 08 153808</td>\n",
              "      <td>12</td>\n",
              "      <td>18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>donald trump read top ten financi tip late sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1741160716</td>\n",
              "      <td>http twittercomrealdonaldtrumpstatus1741160716</td>\n",
              "      <td>new blog post celebr apprentic final lesson le...</td>\n",
              "      <td>2009 05 08 224015</td>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>new blog post celebr apprentic final lesson le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1773561338</td>\n",
              "      <td>http twittercomrealdonaldtrumpstatus1773561338</td>\n",
              "      <td>persona never wallflow rather build wall cle d...</td>\n",
              "      <td>2009 05 12 160728</td>\n",
              "      <td>1399</td>\n",
              "      <td>1965</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>persona never wallflow rather build wall cle d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-242691fa-d0e3-46a2-aa37-6d0d697552f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-242691fa-d0e3-46a2-aa37-6d0d697552f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-242691fa-d0e3-46a2-aa37-6d0d697552f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f48a58f3-7cdf-45cc-b46c-8d4e5e415f37\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f48a58f3-7cdf-45cc-b46c-8d4e5e415f37')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f48a58f3-7cdf-45cc-b46c-8d4e5e415f37 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 41122,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 302794624798576512,\n        \"min\": 1698308935,\n        \"max\": 1219076533354037249,\n        \"num_unique_values\": 41122,\n        \"samples\": [\n          385862325875376128,\n          689804695221600256,\n          664628393921544192\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41122,\n        \"samples\": [\n          \"http twittercomrealdonaldtrumpstatus385862325875376128\",\n          \"http twittercomrealdonaldtrumpstatus689804695221600256\",\n          \"http twittercomrealdonaldtrumpstatus664628393921544192\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40689,\n        \"samples\": [\n          \"sorensenao huffpostukpol realdonaldtrump donaldtrump shake polit like ever could interestingtimesahead\",\n          \"thank join thi solemn day remembr gather sacr soil arlingtonnatl cemeteri honor life deed america great hero man woman lay life freedom memorialdaypictwittercomysyahf7bnu\",\n          \"anyon comprehend great job border patrol law enforc southern border far thi year apprehend 418000 plu illeg immigr way last year mexico veri littl dem congress must act\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 40812,\n        \"samples\": [\n          \"2014 06 19 044551\",\n          \"2011 08 10 171908\",\n          \"2011 02 17 170657\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10130,\n        \"min\": 0,\n        \"max\": 309892,\n        \"num_unique_values\": 12924,\n        \"samples\": [\n          31531,\n          10815,\n          19061\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"favorites\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41501,\n        \"min\": 0,\n        \"max\": 857678,\n        \"num_unique_values\": 16301,\n        \"samples\": [\n          59992,\n          3839,\n          2178\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mentions\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2373,\n        \"samples\": [\n          \"joedmti\",\n          \"jj55334767\",\n          \"realrobharrand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hashtags\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 109,\n        \"samples\": [\n          \"ixzz3ga4vp4cz\",\n          \"19\",\n          \"103\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"geo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40689,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 178
        }
      ],
      "source": [
        "# Chemin de sortie pour le fichier modifié\n",
        "output_file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new_05.csv'\n",
        "\n",
        "# Sauvegarder le fichier\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Les emojis ont été supprimés et le fichier a été sauvegardé sous :\", output_file_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x8dLVIqQ3u5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cImwAQtAUC6z"
      },
      "source": [
        "**Note** : La suppression d'emoji peut négliger des informations importantes. Mais selon les cas les inclure peut amener à des bruits dans la données."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lae5AMoFCaIL"
      },
      "source": [
        "### 9. Traduction des abbréviations et acronymes\n",
        "**Description :** Cette fonction remplace les abbréviations courantes par leur signification complète (ex: \"brb\" devient \"be right back\"). Cela facilite la lecture et l'analyse automatique des textes informels.\n",
        "\n",
        "On pourra utiliser le fichier slang.txt qui contient des Abbréviations et leur signification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbZaEY5cSKDw"
      },
      "source": [
        "Nous allons charger le fichier dans lequel nous avons déjà supprimé les emojis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpqOjMh6SJNl",
        "outputId": "d0daa53d-4ece-4da6-b3d5-f38866f09d3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           id                                            link  \\\n",
            "0  1698308935  http twittercomrealdonaldtrumpstatus1698308935   \n",
            "1  1701461182  http twittercomrealdonaldtrumpstatus1701461182   \n",
            "2  1737479987  http twittercomrealdonaldtrumpstatus1737479987   \n",
            "3  1741160716  http twittercomrealdonaldtrumpstatus1741160716   \n",
            "4  1773561338  http twittercomrealdonaldtrumpstatus1773561338   \n",
            "\n",
            "                                             content               date  \\\n",
            "0  sure tune watch donald trump late night david ...  2009 05 04 205425   \n",
            "1  donald trump appear view tomorrow morn discuss...  2009 05 05 030010   \n",
            "2  donald trump read top ten financi tip late sho...  2009 05 08 153808   \n",
            "3  new blog post celebr apprentic final lesson le...  2009 05 08 224015   \n",
            "4  persona never wallflow rather build wall cle d...  2009 05 12 160728   \n",
            "\n",
            "   retweets  favorites mentions hashtags  geo  \\\n",
            "0       500        868      NaN      NaN  NaN   \n",
            "1        33        273      NaN      NaN  NaN   \n",
            "2        12         18      NaN      NaN  NaN   \n",
            "3        11         24      NaN      NaN  NaN   \n",
            "4      1399       1965      NaN      NaN  NaN   \n",
            "\n",
            "                                     content_cleaned  \n",
            "0  sure tune watch donald trump late night david ...  \n",
            "1  donald trump appear view tomorrow morn discuss...  \n",
            "2  donald trump read top ten financi tip late sho...  \n",
            "3  new blog post celebr apprentic final lesson le...  \n",
            "4  persona never wallflow rather build wall cle d...  \n"
          ]
        }
      ],
      "source": [
        "# Chemin du fichier\n",
        "file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new_05.csv'\n",
        "\n",
        "# Charger le fichier CSV\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7GCcDpdSpk7"
      },
      "source": [
        "Le fichier slang.txt contient des abréviations et leur signification. Nous allons le charger et créer un dictionnaire pour les mapper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sojb-_m9Sl7x",
        "outputId": "1ec48e2d-e4d5-4b8b-bb4d-d524a04fb02d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('ILU=ILU', 'I Love You'), ('7K=Sick', '-D Laugher'), ('BFF', 'Best friends forever')]\n"
          ]
        }
      ],
      "source": [
        "# Chemin du fichier slang.txt\n",
        "slang_path = '/content/drive/My Drive/data mining/slang.txt'\n",
        "\n",
        "# Charger le fichier slang.txt et créer un dictionnaire\n",
        "slang_dict = {}\n",
        "with open(slang_path, 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        # Skip empty lines or lines without a colon\n",
        "        if not line.strip() or ':' not in line:\n",
        "            continue\n",
        "        abbreviation, meaning = line.strip().split(':', 1) # Limit split to 1\n",
        "        slang_dict[abbreviation.strip()] = meaning.strip()\n",
        "\n",
        "# Afficher quelques entrées du dictionnaire pour vérifier\n",
        "print(list(slang_dict.items())[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ry_k1LyJCbvA",
        "outputId": "3ab13529-c74c-47df-9d36-5cc90c18c55a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-181-405aadd88c0b>:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df[string_cols] = df[string_cols].applymap(translator)\n"
          ]
        }
      ],
      "source": [
        "# Function : translator\n",
        "\n",
        "def translator(user_string):\n",
        "    \"\"\"\n",
        "    Remplace les abréviations et acronymes par leur forme complète.\n",
        "\n",
        "    Args:\n",
        "        user_string (str): Le texte contenant des abréviations.\n",
        "\n",
        "    Returns:\n",
        "        str: Le texte avec les abréviations remplacées par leur signification.\n",
        "    \"\"\"\n",
        "    # Check if the input is a string\n",
        "    if isinstance(user_string, str):\n",
        "        # Remplacer les abréviations par leur signification\n",
        "        for abbreviation, meaning in slang_dict.items():\n",
        "            user_string = user_string.replace(abbreviation, meaning)\n",
        "    return user_string\n",
        "\n",
        "# Select only string columns for applying translator function\n",
        "string_cols = df.select_dtypes(include=['object']).columns\n",
        "df[string_cols] = df[string_cols].applymap(translator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOntPyRHSyyt"
      },
      "source": [
        "Nous allons utiliser applymap pour appliquer la fonction translator à toutes les cellules du DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74fAgRT2SwAC",
        "outputId": "4cff2255-537d-4592-da1d-173ed261765c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           id                                            link  \\\n",
            "0  1698308935  http twittercomrealdonaldtrumpstatus1698308935   \n",
            "1  1701461182  http twittercomrealdonaldtrumpstatus1701461182   \n",
            "2  1737479987  http twittercomrealdonaldtrumpstatus1737479987   \n",
            "3  1741160716  http twittercomrealdonaldtrumpstatus1741160716   \n",
            "4  1773561338  http twittercomrealdonaldtrumpstatus1773561338   \n",
            "\n",
            "                                             content               date  \\\n",
            "0  sure tune watch donald trump late night david ...  2009 05 04 205425   \n",
            "1  donald trump appear view tomorrow morn discuss...  2009 05 05 030010   \n",
            "2  donald trump read top ten financi tip late sho...  2009 05 08 153808   \n",
            "3  new blog post celebr apprentic final lesson le...  2009 05 08 224015   \n",
            "4  persona never wallflow rather build wall cle d...  2009 05 12 160728   \n",
            "\n",
            "   retweets  favorites mentions hashtags  geo  \\\n",
            "0       500        868      NaN      NaN  NaN   \n",
            "1        33        273      NaN      NaN  NaN   \n",
            "2        12         18      NaN      NaN  NaN   \n",
            "3        11         24      NaN      NaN  NaN   \n",
            "4      1399       1965      NaN      NaN  NaN   \n",
            "\n",
            "                                     content_cleaned  \n",
            "0  sure tune watch donald trump late night david ...  \n",
            "1  donald trump appear view tomorrow morn discuss...  \n",
            "2  donald trump read top ten financi tip late sho...  \n",
            "3  new blog post celebr apprentic final lesson le...  \n",
            "4  persona never wallflow rather build wall cle d...  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-182-8c2588458431>:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(translator)\n"
          ]
        }
      ],
      "source": [
        "# Appliquer la fonction à toutes les cellules du DataFrame\n",
        "df = df.applymap(translator)\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-WW0456S1z_"
      },
      "source": [
        "Nous allons sauvegarder le DataFrame modifié dans un nouveau fichier nommé fichier_nettoye_02_new_06.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "upGKKD1-S1F6",
        "outputId": "887f3c4d-ccce-4239-ac30-56e8f0ff7b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Les abréviations ont été traduites et le fichier a été sauvegardé sous : /content/drive/My Drive/data mining/fichier_nettoye_02_new_06.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                            link  \\\n",
              "0  1698308935  http twittercomrealdonaldtrumpstatus1698308935   \n",
              "1  1701461182  http twittercomrealdonaldtrumpstatus1701461182   \n",
              "2  1737479987  http twittercomrealdonaldtrumpstatus1737479987   \n",
              "3  1741160716  http twittercomrealdonaldtrumpstatus1741160716   \n",
              "4  1773561338  http twittercomrealdonaldtrumpstatus1773561338   \n",
              "\n",
              "                                             content               date  \\\n",
              "0  sure tune watch donald trump late night david ...  2009 05 04 205425   \n",
              "1  donald trump appear view tomorrow morn discuss...  2009 05 05 030010   \n",
              "2  donald trump read top ten financi tip late sho...  2009 05 08 153808   \n",
              "3  new blog post celebr apprentic final lesson le...  2009 05 08 224015   \n",
              "4  persona never wallflow rather build wall cle d...  2009 05 12 160728   \n",
              "\n",
              "   retweets  favorites mentions hashtags  geo  \\\n",
              "0       500        868      NaN      NaN  NaN   \n",
              "1        33        273      NaN      NaN  NaN   \n",
              "2        12         18      NaN      NaN  NaN   \n",
              "3        11         24      NaN      NaN  NaN   \n",
              "4      1399       1965      NaN      NaN  NaN   \n",
              "\n",
              "                                     content_cleaned  \n",
              "0  sure tune watch donald trump late night david ...  \n",
              "1  donald trump appear view tomorrow morn discuss...  \n",
              "2  donald trump read top ten financi tip late sho...  \n",
              "3  new blog post celebr apprentic final lesson le...  \n",
              "4  persona never wallflow rather build wall cle d...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4774a4e9-890c-4f70-b32d-5fc7af915d81\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>link</th>\n",
              "      <th>content</th>\n",
              "      <th>date</th>\n",
              "      <th>retweets</th>\n",
              "      <th>favorites</th>\n",
              "      <th>mentions</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>geo</th>\n",
              "      <th>content_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1698308935</td>\n",
              "      <td>http twittercomrealdonaldtrumpstatus1698308935</td>\n",
              "      <td>sure tune watch donald trump late night david ...</td>\n",
              "      <td>2009 05 04 205425</td>\n",
              "      <td>500</td>\n",
              "      <td>868</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sure tune watch donald trump late night david ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1701461182</td>\n",
              "      <td>http twittercomrealdonaldtrumpstatus1701461182</td>\n",
              "      <td>donald trump appear view tomorrow morn discuss...</td>\n",
              "      <td>2009 05 05 030010</td>\n",
              "      <td>33</td>\n",
              "      <td>273</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>donald trump appear view tomorrow morn discuss...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1737479987</td>\n",
              "      <td>http twittercomrealdonaldtrumpstatus1737479987</td>\n",
              "      <td>donald trump read top ten financi tip late sho...</td>\n",
              "      <td>2009 05 08 153808</td>\n",
              "      <td>12</td>\n",
              "      <td>18</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>donald trump read top ten financi tip late sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1741160716</td>\n",
              "      <td>http twittercomrealdonaldtrumpstatus1741160716</td>\n",
              "      <td>new blog post celebr apprentic final lesson le...</td>\n",
              "      <td>2009 05 08 224015</td>\n",
              "      <td>11</td>\n",
              "      <td>24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>new blog post celebr apprentic final lesson le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1773561338</td>\n",
              "      <td>http twittercomrealdonaldtrumpstatus1773561338</td>\n",
              "      <td>persona never wallflow rather build wall cle d...</td>\n",
              "      <td>2009 05 12 160728</td>\n",
              "      <td>1399</td>\n",
              "      <td>1965</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>persona never wallflow rather build wall cle d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4774a4e9-890c-4f70-b32d-5fc7af915d81')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4774a4e9-890c-4f70-b32d-5fc7af915d81 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4774a4e9-890c-4f70-b32d-5fc7af915d81');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-451bfd21-6606-4d68-9367-fb3871dd1465\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-451bfd21-6606-4d68-9367-fb3871dd1465')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-451bfd21-6606-4d68-9367-fb3871dd1465 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 41122,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 302794624798576512,\n        \"min\": 1698308935,\n        \"max\": 1219076533354037249,\n        \"num_unique_values\": 41122,\n        \"samples\": [\n          385862325875376128,\n          689804695221600256,\n          664628393921544192\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41122,\n        \"samples\": [\n          \"http twittercomrealdonaldtrumpstatus385862325875376128\",\n          \"http twittercomrealdonaldtrumpstatus689804695221600256\",\n          \"http twittercomrealdonaldtrumpstatus664628393921544192\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40689,\n        \"samples\": [\n          \"sorensenao huffpostukpol realdonaldtrump donaldtrump shake polit like ever could interestingtimesahead\",\n          \"thank join thi solemn day remembr gather sacr soil arlingtonnatl cemeteri honor life deed america great hero man woman lay life freedom memorialdaypictwittercomysyahf7bnu\",\n          \"anyon comprehend great job border patrol law enforc southern border far thi year apprehend 418000 plu illeg immigr way last year mexico veri littl dem congress must act\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 40812,\n        \"samples\": [\n          \"2014 06 19 044551\",\n          \"2011 08 10 171908\",\n          \"2011 02 17 170657\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10130,\n        \"min\": 0,\n        \"max\": 309892,\n        \"num_unique_values\": 12924,\n        \"samples\": [\n          31531,\n          10815,\n          19061\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"favorites\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 41501,\n        \"min\": 0,\n        \"max\": 857678,\n        \"num_unique_values\": 16301,\n        \"samples\": [\n          59992,\n          3839,\n          2178\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mentions\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2373,\n        \"samples\": [\n          \"joedmti\",\n          \"jj55334767\",\n          \"realrobharrand\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hashtags\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 109,\n        \"samples\": [\n          \"ixzz3ga4vp4cz\",\n          \"19\",\n          \"103\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"geo\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"content_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40689,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 184
        }
      ],
      "source": [
        "# Chemin de sortie pour le fichier modifié\n",
        "output_file_path = '/content/drive/My Drive/data mining/fichier_nettoye_02_new_06.csv'\n",
        "\n",
        "# Sauvegarder le fichier\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Les abréviations ont été traduites et le fichier a été sauvegardé sous :\", output_file_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHu3BLtDVHBb"
      },
      "source": [
        "### 10. Normalisation du corpus\n",
        "**Description :** Cette fonction applique plusieurs des prétraitements mentionnés ci-dessus à un ensemble de textes (corpus). Cela permet de standardiser les données avant de les utiliser pour du NLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sssJbnAsViZ1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61vYGxphVlAq",
        "outputId": "aa4c946d-bb7d-42be-e162-236ee3277d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Télécharger les ressources NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialiser le lemmatiseur\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoXULnJCVIgj"
      },
      "outputs": [],
      "source": [
        "# Fonction : normalize_corpus\n",
        "\n",
        "def normalize_corpus(corpus, html_stripping=True, accented_char_removal=True, text_lower_case=True,\n",
        "                    text_lemmatization=True, special_char_removal=True, stopword_removal=True, remove_digits=True):\n",
        "    \"\"\"\n",
        "    Applique un ensemble d'étapes de prétraitement à un corpus de textes.\n",
        "\n",
        "    Args:\n",
        "        corpus (list): Une liste de textes à prétraiter.\n",
        "        html_stripping (bool): Si True, supprime les balises HTML.\n",
        "        accented_char_removal (bool): Si True, supprime les accents.\n",
        "        text_lower_case (bool): Si True, convertit le texte en minuscules.\n",
        "        text_lemmatization (bool): Si True, applique la lemmatisation.\n",
        "        special_char_removal (bool): Si True, supprime les caractères spéciaux.\n",
        "        stopword_removal (bool): Si True, supprime les stopwords.\n",
        "        remove_digits (bool): Si True, supprime les chiffres.\n",
        "\n",
        "    Returns:\n",
        "        list: Le corpus prétraité.\n",
        "    \"\"\"\n",
        "    normalized_corpus = []\n",
        "\n",
        "    for text in corpus:\n",
        "        # Supprimer les balises HTML\n",
        "        if html_stripping:\n",
        "            text = re.sub(r'<[^>]+>', '', text)\n",
        "\n",
        "        # Supprimer les accents\n",
        "        if accented_char_removal:\n",
        "            text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "\n",
        "        # Convertir en minuscules\n",
        "        if text_lower_case:\n",
        "            text = text.lower()\n",
        "\n",
        "        # Supprimer les caractères spéciaux et les chiffres\n",
        "        if special_char_removal:\n",
        "            pattern = r'[^a-zA-Z\\s]' if remove_digits else r'[^a-zA-Z0-9\\s]'\n",
        "            text = re.sub(pattern, '', text)\n",
        "\n",
        "        # Lemmatisation\n",
        "        if text_lemmatization:\n",
        "            tokens = word_tokenize(text)\n",
        "            text = ' '.join([lemmatizer.lemmatize(token) for token in tokens])\n",
        "\n",
        "        # Supprimer les stopwords\n",
        "        if stopword_removal:\n",
        "            tokens = word_tokenize(text)\n",
        "            stop_words = set(stopwords.words('english'))\n",
        "            text = ' '.join([token for token in tokens if token not in stop_words])\n",
        "\n",
        "        normalized_corpus.append(text)\n",
        "\n",
        "    return normalized_corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "40Qhsr9dW5_r",
        "outputId": "0195cc93-1514-4322-ffd2-9b69202223f9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "expected string or bytes-like object, got 'float'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-72a93ba4fda8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Appliquer la fonction normalize_corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m normalized_corpus = normalize_corpus(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mhtml_stripping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-187-754e86d6fc0d>\u001b[0m in \u001b[0;36mnormalize_corpus\u001b[0;34m(corpus, html_stripping, accented_char_removal, text_lower_case, text_lemmatization, special_char_removal, stopword_removal, remove_digits)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Supprimer les balises HTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhtml_stripping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'<[^>]+>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Supprimer les accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/re/__init__.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object, got 'float'"
          ]
        }
      ],
      "source": [
        "# Convertir la colonne 'content' en une liste de textes #The column name is changed from 'text' to 'content'\n",
        "corpus = df['content'].tolist()\n",
        "\n",
        "# Appliquer la fonction normalize_corpus\n",
        "normalized_corpus = normalize_corpus(\n",
        "    corpus,\n",
        "    html_stripping=True,\n",
        "    accented_char_removal=True,\n",
        "    text_lower_case=True,\n",
        "    text_lemmatization=True,\n",
        "    special_char_removal=True,\n",
        "    stopword_removal=True,\n",
        "    remove_digits=True\n",
        ")\n",
        "\n",
        "# Ajouter le corpus prétraité au DataFrame\n",
        "df['normalized_text'] = normalized_corpus\n",
        "\n",
        "# Afficher les premières lignes pour vérifier\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te-YAtt7fejT"
      },
      "source": [
        "Exportation de mon dernier fichier drive 'Mon_dernier_fichier_nettoye_.csv' avec des données standarisées"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYIkvBztVx9Q"
      },
      "outputs": [],
      "source": [
        "# Chemin de sortie pour le fichier modifié\n",
        "output_file_path = '/content/drive/My Drive/data mining/Mon_dernier_fichier_nettoye_.csv'\n",
        "\n",
        "# Sauvegarder le fichier\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Le corpus a été normalisé et le fichier a été sauvegardé sous :\", output_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOD1E6sKfsxR"
      },
      "source": [
        "Nous sommes à la fin de notre projets."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}